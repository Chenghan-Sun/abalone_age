---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. It is the main r file including the related code for the project for the STA 206.

```{r}
library(MASS)
library(ggplot2)
library(GGally)
library(car)
library(leaps)
```

### Part I: data loading and feature engineering
#### Exploratory data analysis
##### Summary statistics
We first read in the data and develope an exploratory data analysis.
```{r}
col_names <- c('sex','length','diameter','height','whole','shucked','viscera','shell','rings')
data <- read.table('../dataset/abalone.txt', header=FALSE, sep=',', col.names= col_names)
is.na(data$frame) #check missing value 
summary(data)
```

It is interested to see the height data has minimum of zero. Aparrently, this is not possible. It might be the reason of the wrong input, but these data points should be excluded.
```{r}
#d_data <- data[data$height == 0,] #get index of error data 
#index_d_data <- as.numeric(rownames(d_data))
#data <- data[-(index_d_data)]
data <- subset(data, data$height != 0)
summary(data)
```
2 observed error data were deleted.

##### Type of data
```{r}
sapply(data, class)
```
It's observed that only sex is qualitative variable, we'll consider indicator variable later.

Also the predictor `whole` should be the linear function of variables `shucked`, `viscera` and `shell`, which is `whole` = `shucked` + `shell` + weight loss during weighing operations 
```{r}
data$loss_1 <- data$whole - data$shucked - data$shell
data$loss_2 <- data$shucked - data$viscera
data$loss_3 <- data$whole - data$shucked
nrow(data[data$loss_1 < 0,])
nrow(data[data$loss_2 < 0,])
nrow(data[data$loss_3 < 0,]) # number of data with whole weight less than sum of other three weights 
data <- subset(data, data$loss_1 >= 0)
data <- subset(data, data$loss_2 >= 0)
data <- subset(data, data$loss_3 >= 0)
summary(data)
```
22+2 = 24 data were removed.

##### 
The ggpairs plot below has same functionality as matrix scatter plot, boxplots, and histogram plots
```{r fig.height=10, fig.width=12, message=FALSE, warning=FALSE}

pdf(file="../fig/MyFig.pdf", height = 10, width = 12)
ggpairs(data, aes(colour=sex, alpha=0.6), title="Pairs plot for abalone dataset") + theme_grey(base_size = 8)
dev.off()

```
1. Determination of response variable: rings. 
2. High correlation -- multicoliearity. 
3. Distributions of F and M are similar w.r.t all predictors --> simplify indicator variable to I and N.
4. Distribution of response are left-skewed -- box-cox.

Pan plots of sex (need pie charts for all predictors?)
```{r}
sex_value <- c(1307, 1342, 1528)
sex <- c("F", "I", "M")
piepercent <- round(100*sex_value/sum(sex_value), 1)
pieplot <- pie(sex_value, labels = piepercent, main="Abalone sex pie chart", col = rainbow(length(sex_value)))
legend("topright", sex, cex = 0.8, fill = rainbow(length(sex_value)))
```
```{r}
sex_value <- c(1307, 1342, 1528)
percent <- round(100*sex_value/sum(sex_value), 1)
bp<- ggplot(data, aes(x='', y='', fill=sex)) + geom_bar(width = 1, stat = "identity") 
pie <- bp + coord_polar("y", start=0)

blank_theme <- theme_minimal()+
  theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.border = element_blank(),
  panel.grid=element_blank(),
  axis.ticks = element_blank(),
  plot.title=element_text(size=14, face="bold")
  )
pie + blank_theme
```

Create a new variable N = M + F, change to binary indicator variable 
```{r}
data['sex'] <- ifelse(data$sex == 'I', 'I', 'N')
data$sex <- as.factor(data$sex)
summary(data)
```
# Part II
Data splitting (training~70%, validation~30%)
```{r}
data <- data[,1:9]
summary(data)
set.seed(40)  #set seed for random number generator
n_data <- nrow(data)
indexes <- sample(1:n_data, size = 0.3*n_data)
data_validation <- data[indexes,]
data_train <- data[-indexes,]
```
Examine the similarity of training set and validation set
```{r}
par(mfrow=c(3,3))
boxplot(data_train$length, data_validation$length, col = 'orange', main = 'length', names=c('train', 'validation'))
boxplot(data_train$diameter, data_validation$diameter, col = 'orange', main = 'diameter', names=c('train', 'validation'))
boxplot(data_train$height, data_validation$height, col = 'orange', main = 'height', names=c('train', 'validation'))
boxplot(data_train$whole, data_validation$whole, col = 'orange', main = 'whole weight', names=c('train', 'validation'))
boxplot(data_train$shucked, data_validation$shucked, col = 'orange', main = 'shucked weight', names=c('train', 'validation'))
boxplot(data_train$viscera, data_validation$viscera, col = 'orange', main = 'viscera weight', names=c('train', 'validation'))
boxplot(data_train$shell, data_validation$shell, col = 'orange', main = 'shell weight', names=c('train', 'validation'))
boxplot(data_train$rings, data_validation$rings, col = 'orange', main = 'rings', names=c('train', 'validation'))
```
The data distribution looks similar. 

The first model: Additive Multiple Linear Regression Model: (consider subsets selection from the pool of all first-order effects of the 8 predictors)
```{r}
Model1 <- lm(rings~sex+length+diameter+height+whole+shucked+viscera+shell, data = data_train)
summary(Model1)
layout(matrix(c(1,2),1,2))
plot(Model1, which =c(1,2), col='blue')
```
- No equal variance, Q-Q plot shows heavy tailed.
- The factor level `I` is the reference level of `sex` predictor.
- From the additive model, predictor `length` is not significant, since `length` and `diameter` are highly correlated. All weight predictors are significant.
- MSE
```{r}
anova(Model1)['Residuals', 3]
```
Box-Cox Transformations:
```{r}
boxcox(Model1)
```
lambda ~ 0 indicates logrithm transformation of rings 
```{r fig.height=2, fig.width=5, message=FALSE, warning=FALSE} 
Model2 <- lm(log(rings)~sex+length+diameter+height+whole+shucked+viscera+shell, data=data_train)
summary(Model2)
anova(Model2)['Residuals', 3]
layout(matrix(c(1,2,3),1,3))
plot(Model2, which =c(1,2), col='blue')
boxcox(Model2)
```
- Residuals vs. fitted value plot still shows nonlinearity, and QQ plot shows right-skewed
We can see R2 increase to 0.6035 and MSE is much smaller.

Pair plot for Model2
```{r fig.height=10, fig.width=12, message=FALSE, warning=FALSE}
# make another dataset with log(rings) for pair plot
#data_log <- data_train
#data_log[,9] <- log(data_log[,9])
#ggpairs(data_log, aes(colour = sex, alpha = 0.6), title="Pairs plot for data in training set after log-transformation") + theme_grey(base_size = 8)
```
No obvious nonlinearity observed.

Multicolinearity 
```{r}
vif(Model2)
```
`whole` has largest vif.

added variable plot:
```{r}
Model2_a <- lm(log(rings)~sex+length+diameter+height+shucked+viscera+shell, data=data_train)
Model2_wo_whole <- residuals(lm(log(rings)~sex+length+diameter+height+shucked+viscera+shell, data=data_train))
fit_whole <- residuals(lm(whole~sex+length+diameter+height+shucked+viscera+shell, data = data_train))
plot(Model2_wo_whole~fit_whole, col='blue', main='added variable plot of whole weight')
abline(lm(Model2_wo_whole~fit_whole), col='red')
```
Added-variable plot for whole implies that whole is of little additional help in explaining rings when other predictors are already in the model.

vif for Model2_a
```{r}
vif(Model2_a)
```
Three terms `length`, `diameter` still have high VIF. Exclude `diameter` since it has largest VIF.
```{r}
Model2_b <- lm(log(rings)~sex+length+height+shucked+viscera+shell, data = data_train)
Model2_wo_diameter <- residuals(lm(log(rings)~sex+length+height+shucked+viscera+shell, data = data_train))
fit_diameter <- residuals(lm(diameter~sex+length+height+shucked+viscera+shell, data = data_train))
plot(Model2_wo_diameter~fit_diameter, col='blue', main='added variable plot of diameter')
abline(lm(Model2_wo_diameter~fit_diameter), col='red')
```
vif for Model1_b
```{r}
vif(Model2_b)
```
VIF for each predictor looks better. But note that we couldn't drop any predictors only based on multicoliearity analysis. 

Part III
Model selection: 
Exhaustive search
```{r}
sub_set <- regsubsets(log(rings)~sex+length+diameter+height+whole+shucked+viscera+shell,data = data_train, nbest = 1, nvmax = 8, method="exhaustive", really.big=T)
sum_sub <- summary(sub_set)
p = as.integer(rownames(sum_sub$which)) + 1 #number of coefficients in each model: p
ssto = sum((log(data_train[,9]) - mean(log(data_train[,9])))^2)
n=nrow(data_train)
sse <- sum_sub$rss
AIC <- n*log(sse/n) + 2*p
BIC <- n*log(sse/n) + log(n)*p
res_sub = cbind(sum_sub$which,sse,sum_sub$rsq,sum_sub$adjr2,sum_sub$cp,BIC,AIC)
res_sub
```
#8 is selected based on smallest BIC criteria.

Using stepwise procedure:
```{r}
Model0 <- lm(log(rings)~1, data = data_train)
# use BIC as criteria since n >> 8
stepwise_BIC_both <- stepAIC(Model0, scope=list(upper=Model2, lower=Model0), direction="both", k=log(n))
stepwise_BIC_both$anova
stepwise_BIC_forw <- stepAIC(Model0, scope=list(upper=Model2, lower=Model0), direction="forward", k=log(n))
stepwise_BIC_forw$anova
stepwise_BIC_back <- stepAIC(Model2, scope=list(upper=~., lower=~1), direction="backward", k=log(n))
stepwise_BIC_back$anova
```
Final Model:
log(rings) ~ shell + shucked + diameter + sex + height + whole + viscera + length
BIC = -9262.857

No re-check of model diagnostics needed since the final model same as Model2.

## Model with interaction term
#### Residual plots with the interaction terms
```{r fig.height=8, fig.width=5, message=FALSE, warning=FALSE} 

res_m2 <- resid(Model2)
par(mfrow=c(7,3))

plot(data_train$length*data_train$diameter,res_m2,xlab="length*diameter", col='blue')
plot(data_train$length*data_train$height,res_m2,xlab="length*height", col='blue')
plot(data_train$length*data_train$whole,res_m2,xlab="length*whole", col='blue')
plot(data_train$length*data_train$shucked,res_m2,xlab="length*shucked", col='blue')
plot(data_train$length*data_train$viscera,res_m2,xlab="length*viscera", col='blue')
plot(data_train$length*data_train$shell,res_m2,xlab="length*shell", col='blue')

plot(data_train$diameter*data_train$height,res_m2,xlab="diameter*height", col='blue')
plot(data_train$diameter*data_train$whole,res_m2,xlab="diameter*whole", col='blue')
plot(data_train$diameter*data_train$shucked,res_m2,xlab="diameter*schuked", col='blue')
plot(data_train$diameter*data_train$viscera,res_m2,xlab="diameter*viscera", col='blue')
plot(data_train$diameter*data_train$shell,res_m2,xlab="diameter*shell", col='blue')

plot(data_train$height*data_train$whole,res_m2,xlab="height*whole", col='blue')
plot(data_train$height*data_train$shucked,res_m2,xlab="height*shucked", col='blue')
plot(data_train$height*data_train$viscera,res_m2,xlab="height*viscera", col='blue')
plot(data_train$height*data_train$shell,res_m2,xlab="height*shell", col='blue')

plot(data_train$whole*data_train$shucked,res_m2,xlab="whole*shucked", col='blue')
plot(data_train$whole*data_train$viscera,res_m2,xlab="whole*viscera", col='blue')
plot(data_train$whole*data_train$shell,res_m2,xlab="whole*shell", col='blue')

plot(data_train$shucked*data_train$viscera,res_m2,xlab="shucked*viscera", col='blue')
plot(data_train$shucked*data_train$shell,res_m2,xlab="shucked*shell", col='blue')

plot(data_train$viscera*data_train$shell,res_m2,xlab="viscera*shell", col='blue')
```

## define Model4 as interaction full model based on Model2
```{r}
Model3 <- lm(log(rings) ~.^2,data=data_train)
length(Model3$coefficients) #number of coefficients
```

Model Diagnostics
```{r fig.height=2, fig.width=5, message=FALSE, warning=FALSE}
#define the new model
Model4 <- lm(log(rings)~sex+length+diameter+height+whole+shucked+viscera+shell+sex:length+sex:height+length:diameter+length:whole+length:shucked, data=data_train)
anova(Model4)['Residuals', 3]
layout(matrix(c(1,2,3),1,3))
plot(Model4, which =c(1,2), col='blue')
boxcox(Model4)
```

#Exhaustive search
```{r}
m4_sub_set <- regsubsets(log(rings)~.^2,data = data_train, nbest = 1, nvmax = 36, method="exhaustive", really.big=T)
m4_sum_sub <- summary(m4_sub_set)
m4_p = as.integer(rownames(m4_sum_sub$which)) + 1 #number of coefficients in each model: p
m4_ssto = sum((log(data_train[,9]) - mean(log(data_train[,9])))^2)
m4_n=nrow(data_train)
m4_sse <- m4_sum_sub$rss
m4_AIC <- m4_n*log(m4_sse/m4_n) + 2*m4_p
m4_BIC <- m4_n*log(m4_sse/m4_n) + log(m4_n)*m4_p
m4_res_sub = cbind(m4_sum_sub$which,m4_sse,m4_sum_sub$rsq,m4_sum_sub$adjr2,m4_sum_sub$cp,m4_BIC,m4_AIC)
colnames(m4_res_sub)=c(colnames(m4_sum_sub$which),"sse", "R^2", "R^2_a", "Cp", "BIC", "AIC")
m4_res_sub
```
Interaction terms `sexN:height` `length:diameter` `length:whole` `length:shucked` were keeped based on BIC criteria. 

Using stepwise procedure:
```{r}
# Using Model2 as lower model
# use BIC as criteria since n >> 8
m4_stepwise_BIC_both <- stepAIC(Model0, scope=list(upper=Model3, lower=Model0), direction="both", k=log(n))
m4_stepwise_BIC_both$anova
m4_stepwise_BIC_forw <- stepAIC(Model0, scope=list(upper=Model3, lower=Model0), direction="forward", k=log(n))
m4_stepwise_BIC_forw$anova
m4_stepwise_BIC_back <- stepAIC(Model3, scope=list(upper=~., lower=Model0), direction="backward", k=log(n))
m4_stepwise_BIC_back$anova
```
Final Model:
log(rings) ~ sex + length + diameter + height + whole + shucked +  viscera + shell + sex:height + length:diameter + length:whole + length:shucked
with BIC  = -9722.491, which is smaller than Model2.

Model Diagnostics 
```{r fig.height=2, fig.width=5, message=FALSE, warning=FALSE}
#define the new model
Model5 <- lm(log(rings)~sex+length+diameter+height+whole+shucked+viscera+shell+sex:height+length:diameter+length:whole+length:shucked, data=data_train)
anova(Model5)['Residuals', 3]
layout(matrix(c(1,2,3),1,3))
plot(Model5, which =c(1,2), col='blue')
boxcox(Model5)
```
The residual vs. fitted plot shows constant error variance. The Q-Q plot indicates slight heavy tailed. The box-cox procedure shows no further transformation needed.

## Model with second order effects 
#### Residual plots with the second order terms
```{r fig.height=8, fig.width=5, message=FALSE, warning=FALSE} 
res_m2 <- resid(model2)
par(mfrow=c(4,2))
plot(data_train$length*data_train$length,res_m2,xlab="length*length", col='blue')
plot(data_train$diameter*data_train$diameter,res_m2,xlab="diameter*diameter", col='blue')
plot(data_train$height*data_train$height,res_m2,xlab="height*height", col='blue')
plot(data_train$whole*data_train$whole,res_m2,xlab="whole*whole", col='blue')
plot(data_train$shucked*data_train$shucked,res_m2,xlab="shucked*shucked", col='blue')
plot(data_train$shell*data_train$shell,res_m2,xlab="shell*shell", col='blue')
plot(data_train$viscera*data_train$viscera,res_m2,xlab="viscera*viscera", col='blue')
plot(data_train$shell*data_train$shell,res_m2,xlab="shell*shell", col='blue')
```

#### Plots of each predictor versus the response
```{r fig.height=8, fig.width=5, message=FALSE, warning=FALSE} 
par(mfrow=c(4,2))
plot(data_train$length,data_train$rings,xlab="length",ylab="rings", col='blue')
plot(data_train$diameter,data_train$rings,xlab="diameter",ylab="rings", col='blue')
plot(data_train$height,data_train$rings,xlab="height",ylab="rings", col='blue')
plot(data_train$whole,data_train$rings,xlab="whole",ylab="rings", col='blue')
plot(data_train$shucked,data_train$rings,xlab="shucked",ylab="rings", col='blue')
plot(data_train$viscera,data_train$rings,xlab="viscera",ylab="rings", col='blue')
plot(data_train$shell,data_train$rings,xlab="shell",ylab="rings", col='blue')
```

## define Model6 as second-order full model based on Model5
```{r}
Model6 <- lm(log(rings)~sex+length+diameter+height+whole+shucked+viscera+shell+sex:height+length:diameter+length:whole+length:shucked+I(length^2)+I(diameter^2)+I(height^2)+I(whole^2)+I(shucked^2)+I(viscera^2)+I(shell^2), data=data_train)
length(Model6$coefficients) #number of coefficients
anova(Model6)
```
From the ANOVA table, interaction term `length:diameter` is dropped, second order terms `I(length^2)`, `I(diameter^2)`, `I(height^2)`, and `I(shucked^2)` were added to new model. 

Model Diagnostics
```{r fig.height=2, fig.width=5, message=FALSE, warning=FALSE}
#define the new model7
Model7 <- lm(log(rings)~sex+length+diameter+height+whole+shucked+viscera+shell+sex:height+length:whole+length:shucked+I(length^2)+I(diameter^2)+I(height^2)+I(shucked^2), data=data_train)
anova(Model7)['Residuals', 3]
layout(matrix(c(1,2,3),1,3))
plot(Model7, which =c(1,2), col='blue')
boxcox(Model7)
```
No obvious improvement than Model5.

#Exhaustive search
```{r}
m7_sub_set <- regsubsets(log(rings)~sex+length+diameter+height+whole+shucked+viscera+shell+sex:height+length:diameter+length:whole+length:shucked+I(length^2)+I(diameter^2)+I(height^2)+I(whole^2)+I(shucked^2)+I(viscera^2)+I(shell^2), data = data_train, nbest = 1, nvmax = 19 , method="exhaustive", really.big=T)
m7_sum_sub <- summary(m7_sub_set)
m7_p = as.integer(rownames(m7_sum_sub$which)) + 1 #number of coefficients in each model: p
m7_ssto = sum((log(data_train[,9]) - mean(log(data_train[,9])))^2)
m7_n=nrow(data_train)
m7_sse <- m7_sum_sub$rss
m7_AIC <- m7_n*log(m7_sse/m7_n) + 2*m7_p
m7_BIC <- m7_n*log(m7_sse/m7_n) + log(m7_n)*m7_p
m7_res_sub = cbind(m7_sum_sub$which,m7_sse,m7_sum_sub$rsq,m7_sum_sub$adjr2,m7_sum_sub$cp,m7_BIC,m7_AIC)
colnames(m7_res_sub)=c(colnames(m7_sum_sub$which),"sse", "R^2", "R^2_a", "Cp", "BIC", "AIC")
m7_res_sub
```
Additive term `length` is dropped, second order terms `I(height^2)` `I(shucked^2)` were keeped based on BIC criteria. 

Using stepwise procedure:
```{r}
# Using Model5 as lower model
# use BIC as criteria since n >> 10
m6_stepwise_BIC_both <- stepAIC(Model5, scope=list(upper=Model6, lower=Model5), direction="both", k=log(n))
m6_stepwise_BIC_both$anova
print('next')
m6_stepwise_BIC_forw <- stepAIC(Model5, scope=list(upper=Model6, lower=Model5), direction="forward", k=log(n))
m6_stepwise_BIC_forw$anova
m6_stepwise_BIC_back <- stepAIC(Model6, scope=list(upper=Model6, lower=Model5), direction="backward", k=log(n))
m6_stepwise_BIC_back$anova
```


